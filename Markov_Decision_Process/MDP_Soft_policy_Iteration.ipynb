{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement learning: Problem set 3 - soft policy iteration\n",
    "\n",
    "### Juan Felipe Godoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem set I will implement the Soft Policy iteration in the MDP problem we have been working on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial set up\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties of the MDP\n",
    "N = 100 # Number of states\n",
    "q_low = 0.51 #probability of action_low\n",
    "q_high = 0.6 #probability of action_high\n",
    "c_low = 0 #cost of action low\n",
    "c_high = 0.01 #cost of action high\n",
    "p = 0.5 #arrival rate\n",
    "gamma=0.9 # discount factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8 0.2 0.  ... 0.  0.  0. ]\n",
      " [0.3 0.5 0.2 ... 0.  0.  0. ]\n",
      " [0.  0.3 0.5 ... 0.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 0.5 0.2 0. ]\n",
      " [0.  0.  0.  ... 0.3 0.5 0.2]\n",
      " [0.  0.  0.  ... 0.  0.3 0.7]]\n"
     ]
    }
   ],
   "source": [
    "# Action high\n",
    "\n",
    "m_high = np.zeros(shape=(N,N))\n",
    "np.fill_diagonal(m_high,(p*q_high)+(1-p)*(1-q_high))\n",
    "\n",
    "# right\n",
    "for i in range(N-1):\n",
    "    if i != N-1:\n",
    "        m_high[i][i+1]=p*(1-q_high)\n",
    "    if i == 0:\n",
    "        m_high[i][i+1]=0.2\n",
    "        m_high[i][i]=0.8\n",
    "\n",
    "# Left\n",
    "for i in range(N):\n",
    "    if i != 0:\n",
    "        m_high[i][i-1]=(1-p)*(q_high)\n",
    "    if i == N-1:\n",
    "        m_high[i][i-1]=0.3\n",
    "        m_high[i][i]=0.7\n",
    "\n",
    "print(m_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.755 0.245 0.    ... 0.    0.    0.   ]\n",
      " [0.255 0.5   0.245 ... 0.    0.    0.   ]\n",
      " [0.    0.255 0.5   ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.    0.    0.    ... 0.5   0.245 0.   ]\n",
      " [0.    0.    0.    ... 0.255 0.5   0.245]\n",
      " [0.    0.    0.    ... 0.    0.255 0.745]]\n"
     ]
    }
   ],
   "source": [
    "# Action low         \n",
    "m_low = np.zeros(shape=(N,N))\n",
    "np.fill_diagonal(m_low,(p*q_low)+(1-p)*(1-q_low))\n",
    "\n",
    "# right\n",
    "for i in range(N-1):\n",
    "    if i != N-1:\n",
    "        m_low[i][i+1]=p*(1-q_low)\n",
    "    if i == 0:\n",
    "        m_low[i][i+1]=0.245\n",
    "        m_low[i][i]=0.755\n",
    "# Left\n",
    "for i in range(N):\n",
    "    if i != 0:\n",
    "        m_low[i][i-1]=(1-p)*(q_low)\n",
    "    if i ==N-1:\n",
    "        m_low[i][i-1]=0.255\n",
    "        m_low[i][i]=0.745\n",
    "print(m_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function\n",
    "def reward (q,x):    \n",
    "    if q == q_low:\n",
    "        r = -(x/N)**2 -c_low\n",
    "    if  q == q_high:\n",
    "        r = -(x/N)**2 -c_high   \n",
    "    return r\n",
    "\n",
    "def soft_reward (q,x):    \n",
    "    r_1 = -(x/N)**2 - c_low\n",
    "    r_2 = -(x/N)**2 - c_high\n",
    "    r = q[0]*r_1 + q[1]*r_2\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I included a new reward function that outputs the reward based on the stochastic nature of the problem. With probability q takes the calculates the reward of the action low and w.p. 1 -q the reward of the other action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine feature map:\n",
    "def fine_feature (N,x):\n",
    "    return np.eye(N)[x]\n",
    "\n",
    "# Coarse feature map\n",
    "def coarse_feature(N,x):\n",
    "    final_vector = []\n",
    "    for i in range(1,int(N/5)+1):\n",
    "        lower_bound = 5*(i-1)\n",
    "        upper_bound =5*i-1\n",
    "        if lower_bound <= x <= upper_bound:\n",
    "            final_vector.append(1)\n",
    "        else:\n",
    "            final_vector.append(0)\n",
    "    return np.array(final_vector)\n",
    "\n",
    "\n",
    "# Piecewise linear feature\n",
    "def piecewise_feature(N,x):\n",
    "    v1 = coarse_feature(N,x)\n",
    "    v2 = coarse_feature(N,x)\n",
    "    v3 = []\n",
    "    for i in range(1,int(N/5)+1):\n",
    "        v3.append((x-5*(i-1))/5)\n",
    "    final_vector=np.multiply(v3,v2)\n",
    "    return np.append(v1,final_vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def feature_maps(maps,N,x):\n",
    "    if maps == \"fine\":\n",
    "        phi = fine_feature (N,x)\n",
    "    elif maps == 'coarse':\n",
    "        phi = coarse_feature(N,x)\n",
    "    elif maps == 'piece':\n",
    "        phi = piecewise_feature(N,x)\n",
    "    return phi\n",
    "\n",
    "def theta_vector(maps,N):\n",
    "    if maps == \"fine\":\n",
    "        theta = np.zeros(N) \n",
    "    elif maps == \"coarse\":\n",
    "        theta = np.zeros(int(N/5))\n",
    "    elif maps == \"piece\":\n",
    "        theta = np.zeros(2*int(N/5))\n",
    "    return theta  \n",
    "\n",
    "\n",
    "def translate_policy(policy):\n",
    "    return ['lazy' if i[0]==1 else 'aggressive' for i in policy]\n",
    "\n",
    "def reverse_policy(policy):\n",
    "    return[0 if i=='lazy' else 1 for i in policy]\n",
    "\n",
    "def translate_policy_servicerate(policy):\n",
    "    return [0.51 if i == 'lazy' else 0.60 for i in policy]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I define the function defined as soft_LSTD which in comparison of the previous LSTD (Homework 2) recieves the uniform policy $\\pi_{1}(a/X)=1/|A|$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft LSTD\n",
    "\n",
    "def soft_LSTD(N,max_iter,initial_state,maps,gamma,policy,policy_vector:None,m_low,m_high,q_low,q_high):\n",
    "    value_vector = np.zeros(N)\n",
    "    theta = theta_vector(maps,N)\n",
    "    value = np.zeros(N)\n",
    "    s = initial_state \n",
    "\n",
    "    \n",
    "    # Define matrix by policy\n",
    "    if policy == 'lazy':\n",
    "        matrix = m_low\n",
    "    elif policy == 'aggressive':\n",
    "        matrix = np.vstack([m_low[0:50,:],m_high[50:N,:]])\n",
    "\n",
    "   # New option of policy: Uniform\n",
    "   # Build the matrix with the transition probabilities based on the random selction.     \n",
    "    elif policy == 'uniform':\n",
    "        matrix = np.zeros((N,N))\n",
    "\n",
    "        for pi,ni in zip(policy_vector,list(range(N))):  \n",
    "           \n",
    "            row = np.multiply(m_low[ni,:],pi[0]) + np.multiply(m_high[ni,:],(pi[1]))\n",
    "            \n",
    "            matrix[ni,:] = row\n",
    "         \n",
    "             \n",
    "    elif policy =='optimal':\n",
    "        matrix = np.zeros((N,N))\n",
    "        for pi,ni in zip(policy_vector,list(range(N))):\n",
    "            if pi == 'lazy':\n",
    "                row = m_low[ni,:]\n",
    "            elif pi == 'aggressive':\n",
    "                row = m_high[ni,:]\n",
    "            matrix[ni,:] = row\n",
    "\n",
    "\n",
    "    A_B_matrix = 0\n",
    "    b = 0\n",
    "    total_reward = 0\n",
    "    # Iteration\n",
    "    for t in range(max_iter):\n",
    "        # reward vector\n",
    "        reward_vector = []\n",
    "        if policy == 'lazy':\n",
    "            q=q_low\n",
    "            \n",
    "            for x in range(0,N):\n",
    "                reward_vector.append(reward(q,x))\n",
    "        \n",
    "        elif policy == 'aggressive':\n",
    "            for x in range(0,N):\n",
    "                if x < 50:\n",
    "                    q=q_low\n",
    "                else:\n",
    "                    q=q_high\n",
    "                reward_vector.append(reward(q,x))\n",
    "\n",
    "        elif policy =='optimal':\n",
    "            for pi,ni in zip(policy_vector,list(range(N))):\n",
    "                if pi == 'lazy':\n",
    "                    q=q_low\n",
    "                elif pi == 'aggressive':\n",
    "                    q=q_high\n",
    "                reward_vector.append(reward(q,ni))\n",
    "        # Calculate the reward of the policy in each iteration\n",
    "        elif policy == 'uniform':\n",
    "            for pi,ni in zip(policy_vector,list(range(N))):\n",
    "                reward_vector.append(soft_reward(pi,ni))\n",
    "\n",
    "\n",
    "        s_pr = np.random.choice(list(range(0,100)), p=list(matrix[s]))\n",
    "        mapping_x = np.matrix(feature_maps(maps,N,s))\n",
    "        mapping_next = np.matrix(feature_maps(maps,N,s_pr))\n",
    "        \n",
    "        A_B_matrix += mapping_x.T*(mapping_x - gamma*mapping_next)\n",
    "        b +=reward_vector[s]*mapping_x\n",
    "        total_reward += reward_vector[s]\n",
    "        s = s_pr\n",
    "\n",
    "    A_B_matrix = np.linalg.pinv(A_B_matrix)\n",
    "    theta = b*A_B_matrix    \n",
    "\n",
    "    \n",
    "    for j in range (N):\n",
    "        value[j] = np.dot(theta, feature_maps(maps,N,j))\n",
    "        \n",
    "    return total_reward,s,value_vector  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell I introduce one of the main changes compared to the previous homework. \n",
    "Instead of improving the policy by selecting the action that maximizes the $\\hat{Q}_k (a/x)$ we update the policy following the formula suggested in the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the q function : Policy improvement\n",
    "def q_function(values,gamma,eta,optimal_policy):\n",
    "    for x in range(N):\n",
    "        values_list = np.zeros(2)\n",
    "        for q,m,n,pi in zip([q_low,q_high],[m_low,m_high],[0,1],['lazy','aggressive']):\n",
    "            values[n] = reward(q,x) + 0.5*gamma*m[x,:].dot(values)\n",
    "        # Policy update        \n",
    "        optimal_policy[x,0]= optimal_policy[x,0]*np.exp(eta*values[0])/(optimal_policy[x,0]*np.exp(eta*values[0]) + optimal_policy[x,1]*np.exp(eta * values[1]))\n",
    "        optimal_policy[x,1] = 1-optimal_policy[x,0]\n",
    "    return optimal_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft policy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:18<00:00,  3.78s/it]\n",
      "100%|██████████| 100/100 [05:29<00:00,  3.29s/it]\n",
      "100%|██████████| 100/100 [05:43<00:00,  3.43s/it]\n",
      "100%|██████████| 100/100 [05:31<00:00,  3.32s/it]\n",
      "100%|██████████| 100/100 [05:34<00:00,  3.35s/it]\n",
      "100%|██████████| 100/100 [05:07<00:00,  3.07s/it]\n",
      "100%|██████████| 100/100 [05:07<00:00,  3.08s/it]\n",
      "100%|██████████| 100/100 [05:26<00:00,  3.27s/it]\n",
      "100%|██████████| 100/100 [05:18<00:00,  3.19s/it]\n",
      "100%|██████████| 100/100 [05:18<00:00,  3.18s/it]\n",
      "100%|██████████| 10/10 [54:55<00:00, 329.59s/it]\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=['mapping','policy','eta','values','final_state','total_reward'])\n",
    "mapping = 'piece'\n",
    "policy = 'uniform'\n",
    "K = 100\n",
    "s_1 = 99\n",
    "etas = np.logspace(-2,2, num = 10)\n",
    "\n",
    "for eta in tqdm(etas):\n",
    "    policy_updated = np.zeros((100,2)) + 0.5\n",
    "    reward_value = 0\n",
    "    for k in tqdm(range(K)):\n",
    "        total_reward_1,s_1,value_vector_1 = soft_LSTD(max_iter=10000,N=100,initial_state=s_1,maps=mapping,gamma=0.9,policy=policy,policy_vector = policy_updated, m_low=m_low,m_high=m_high,q_high=q_high,q_low=q_low)\n",
    "        reward_value += total_reward_1\n",
    "        policy_updated = q_function(value_vector_1,gamma,eta,policy_updated)\n",
    "        \n",
    "    result = result.append({'mapping':mapping,'policy':policy,'eta':eta,'values':value_vector_1,'final_state':s_1,'total_reward':reward_value}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(' Change of total reward vs. eta ')\n",
    "plt.xlabel('Eta')\n",
    "plt.ylabel('total reward')\n",
    "ax.plot(result['eta'], result['total_reward'],color = 'g')\n",
    "ax.set_xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see from the figure above is that, on average, the total reward decreases as the $\\eta$ increases. However, we can also notice that for relatively small values for the $\\eta$, the total reward is constant and at a tipping point, it starts to decrease. \n",
    "\n",
    "This behavior supports the theoretical results we saw in class, suggesting that selecting values for  $\\eta$ to low or high will result in extremely different scenarios. For our particular case we can conclude that the values of $\\eta$ in the range of $10^{-2} and 10^{0}$ yield better results.  \n",
    "\n",
    "Finally, we can also expect that results in the scenario with the soft_policy are better than those compared to the hard policy."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e06ff7da33dc9620448857a90ad8b5f428f0d573d205a934d2841c8aee45ea32"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
